{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "from scipy.misc import imresize\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "def get_img(data_path):\n",
    "    # Getting image array from path:\n",
    "    img_size = 64\n",
    "    img = io.imread(data_path)\n",
    "    img = imresize(img, (img_size, img_size, 3))\n",
    "    return img\n",
    "\n",
    "def get_dataset(dataset_path=r'F:\\js\\Dog-Cat-Classifier\\Data\\Train_Data'):\n",
    "    # Getting all data from data path:\n",
    "    try:\n",
    "        X = np.load(r'F:\\js\\Dog-Cat-Classifier\\Data\\npy_train_data\\X.npy')\n",
    "        Y = np.load(r'F:\\js\\Dog-Cat-Classifier\\Data\\npy_train_data\\Y.npy')\n",
    "    except:\n",
    "        labels = listdir(dataset_path) # Geting labels\n",
    "        print('Categories:\\n', labels)\n",
    "        len_datas = 0\n",
    "        for label in labels:\n",
    "            len_datas += len(listdir(dataset_path+'/'+label))\n",
    "        X = np.zeros((len_datas, 64, 64, 3), dtype='float64')\n",
    "        Y = np.zeros(len_datas)\n",
    "        count_data = 0\n",
    "        count_categori = [-1,''] # For encode labels\n",
    "        for label in labels:\n",
    "            datas_path = dataset_path+'/'+label\n",
    "            for data in listdir(datas_path):\n",
    "                img = get_img(datas_path+'/'+data)\n",
    "                X[count_data] = img\n",
    "                # For encode labels:\n",
    "                if label != count_categori[1]:\n",
    "                    count_categori[0] += 1\n",
    "                    count_categori[1] = label\n",
    "                Y[count_data] = count_categori[0]\n",
    "                count_data += 1\n",
    "        # Create dateset:\n",
    "        import keras\n",
    "        Y = keras.utils.to_categorical(Y)\n",
    "        import os\n",
    "        if not os.path.exists('F:\\js\\Dog-Cat-Classifier\\Data/npy_train_data/'):\n",
    "            os.makedirs('F:\\js\\Dog-Cat-Classifier\\Data/npy_train_data/')\n",
    "        np.save(r'F:\\js\\Dog-Cat-Classifier\\Data\\npy_train_data\\X.npy', X)\n",
    "        np.save(r'F:\\js\\Dog-Cat-Classifier\\Data\\npy_train_data\\Y.npy', Y)\n",
    "        \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    return X, X_test, Y, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "def save_model(model):\n",
    "    if not os.path.exists('F:\\js\\Dog-Cat-Classifier\\Data/Model/'):\n",
    "        os.makedirs('F:\\js\\Dog-Cat-Classifier\\Data/Model/')\n",
    "    model_json = model.to_json()\n",
    "    with open(\"F:\\js\\Dog-Cat-Classifier\\Data/Model/model.json\", \"w\") as model_file:\n",
    "        model_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"Data/Model/weights.h5\")\n",
    "    print('Model and weights saved')\n",
    "    return\n",
    "\n",
    "def get_model(num_classes=2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "save_model(get_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "def train_model(model, X, X_test, Y, Y_test):\n",
    "    checkpoints = []\n",
    "    if not os.path.exists('F:\\js\\Dog-Cat-Classifier\\Data/Checkpoints/'):\n",
    "        os.makedirs('F:\\js\\Dog-Cat-Classifier\\Data/Checkpoints/')\n",
    "    checkpoints.append(ModelCheckpoint('F:\\js\\Dog-Cat-Classifier\\Data/Checkpoints/best_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1))\n",
    "    checkpoints.append(TensorBoard(log_dir='F:\\js\\Dog-Cat-Classifier\\Data/Checkpoints/./logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None))\n",
    "\n",
    "    # Creates live data:\n",
    "    # For better yield. The duration of the training is extended.\n",
    "\n",
    "    # If you don't want, use this:\n",
    "    # model.fit(X, Y, batch_size=10, epochs=25, validation_data=(X_test, Y_test), shuffle=True, callbacks=checkpoints)\n",
    "\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
    "    generated_data.fit(X)\n",
    "    import numpy\n",
    "    model.fit_generator(generated_data.flow(X, Y, batch_size=10), steps_per_epoch=X.shape[0], epochs=25, validation_data=(X_test, Y_test), callbacks=checkpoints)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1260/1260 [==============================] - 109s 86ms/step - loss: 1.3534 - acc: 0.5226 - val_loss: 0.6886 - val_acc: 0.4929\n",
      "Epoch 2/25\n",
      "1260/1260 [==============================] - 84s 67ms/step - loss: 0.6973 - acc: 0.5352 - val_loss: 0.6731 - val_acc: 0.5250\n",
      "Epoch 3/25\n",
      "1260/1260 [==============================] - 84s 67ms/step - loss: 0.6955 - acc: 0.5433 - val_loss: 0.6856 - val_acc: 0.4929\n",
      "Epoch 4/25\n",
      "1260/1260 [==============================] - 85s 68ms/step - loss: 0.6908 - acc: 0.5670 - val_loss: 0.6894 - val_acc: 0.5000\n",
      "Epoch 5/25\n",
      "1260/1260 [==============================] - 85s 67ms/step - loss: 0.6854 - acc: 0.5820 - val_loss: 0.6587 - val_acc: 0.5679\n",
      "Epoch 6/25\n",
      "1260/1260 [==============================] - 84s 67ms/step - loss: 0.6369 - acc: 0.6466 - val_loss: 0.6464 - val_acc: 0.5679\n",
      "Epoch 7/25\n",
      "1260/1260 [==============================] - 84s 67ms/step - loss: 0.6134 - acc: 0.6700 - val_loss: 0.6268 - val_acc: 0.6107\n",
      "Epoch 8/25\n",
      "1260/1260 [==============================] - 84s 66ms/step - loss: 0.5958 - acc: 0.6943 - val_loss: 0.7221 - val_acc: 0.6179\n",
      "Epoch 9/25\n",
      "1260/1260 [==============================] - 85s 67ms/step - loss: 0.5779 - acc: 0.7079 - val_loss: 0.5699 - val_acc: 0.6964\n",
      "Epoch 10/25\n",
      "1260/1260 [==============================] - 83s 66ms/step - loss: 0.5664 - acc: 0.7177 - val_loss: 0.6073 - val_acc: 0.6643\n",
      "Epoch 11/25\n",
      "1260/1260 [==============================] - 83s 66ms/step - loss: 0.5454 - acc: 0.7333 - val_loss: 0.6135 - val_acc: 0.6607\n",
      "Epoch 12/25\n",
      "1260/1260 [==============================] - 83s 66ms/step - loss: 0.5283 - acc: 0.7428 - val_loss: 0.5661 - val_acc: 0.7286\n",
      "Epoch 13/25\n",
      "1260/1260 [==============================] - 81s 64ms/step - loss: 0.5306 - acc: 0.7471 - val_loss: 0.5831 - val_acc: 0.7000\n",
      "Epoch 14/25\n",
      "1260/1260 [==============================] - 107s 85ms/step - loss: 0.5171 - acc: 0.7557 - val_loss: 0.8982 - val_acc: 0.6893\n",
      "Epoch 15/25\n",
      "1260/1260 [==============================] - 108s 86ms/step - loss: 0.5142 - acc: 0.7584 - val_loss: 0.7590 - val_acc: 0.6464\n",
      "Epoch 16/25\n",
      "1260/1260 [==============================] - 89s 71ms/step - loss: 0.5087 - acc: 0.7633 - val_loss: 0.6557 - val_acc: 0.7143\n",
      "Epoch 17/25\n",
      "1260/1260 [==============================] - 83s 66ms/step - loss: 0.4920 - acc: 0.7722 - val_loss: 0.7671 - val_acc: 0.6750\n",
      "Epoch 18/25\n",
      "1260/1260 [==============================] - 84s 67ms/step - loss: 0.4885 - acc: 0.7739 - val_loss: 0.7801 - val_acc: 0.6821\n",
      "Epoch 19/25\n",
      "1260/1260 [==============================] - 92s 73ms/step - loss: 0.4880 - acc: 0.7717 - val_loss: 0.7745 - val_acc: 0.6643\n",
      "Epoch 20/25\n",
      "1260/1260 [==============================] - 87s 69ms/step - loss: 0.5048 - acc: 0.7658 - val_loss: 0.6192 - val_acc: 0.6929\n",
      "Epoch 21/25\n",
      "1260/1260 [==============================] - 87s 69ms/step - loss: 0.4872 - acc: 0.7790 - val_loss: 0.6373 - val_acc: 0.6857\n",
      "Epoch 22/25\n",
      "1260/1260 [==============================] - 90s 71ms/step - loss: 0.4735 - acc: 0.7788 - val_loss: 0.7320 - val_acc: 0.6964\n",
      "Epoch 23/25\n",
      "1260/1260 [==============================] - 96s 76ms/step - loss: 0.4763 - acc: 0.7765 - val_loss: 0.9096 - val_acc: 0.6679\n",
      "Epoch 24/25\n",
      "1260/1260 [==============================] - 87s 69ms/step - loss: 0.4719 - acc: 0.7804 - val_loss: 0.6818 - val_acc: 0.6786\n",
      "Epoch 25/25\n",
      "1260/1260 [==============================] - 90s 71ms/step - loss: 0.4694 - acc: 0.7891 - val_loss: 0.6505 - val_acc: 0.6857\n",
      "Model and weights saved\n"
     ]
    }
   ],
   "source": [
    "X, X_test, Y, Y_test = get_dataset()\n",
    "model = get_model(len(Y[0]))\n",
    "import numpy\n",
    "model = train_model(model, X, X_test, Y, Y_test)\n",
    "save_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def predict(model, X):\n",
    "    return model.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possibilities:\n",
      "[[ <Cat>  <Dog> ]]\n",
      "[[0.04618423 0.9203562 ]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "img_dir = sys.argv[1]\n",
    "img = get_img(r'F:\\js\\Dog-Cat-Classifier\\test_dog.jpg')\n",
    "\n",
    "import numpy as np\n",
    "X = np.zeros((1, 64, 64, 3), dtype='float64')\n",
    "X[0] = img\n",
    "# Getting model:\n",
    "model_file = open('F:\\js\\Dog-Cat-Classifier\\Data\\Model\\model.json', 'r')\n",
    "model = model_file.read()\n",
    "model_file.close()\n",
    "model = model_from_json(model)\n",
    "# Getting weights\n",
    "model.load_weights(\"F:\\js\\Dog-Cat-Classifier\\Data\\Model\\weights.h5\")\n",
    "print('Possibilities:\\n[[ <Cat>  <Dog> ]]\\n' + str(predict(model, X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
